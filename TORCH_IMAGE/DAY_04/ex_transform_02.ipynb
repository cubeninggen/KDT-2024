{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torchvison 제공 이미지 전처리 관련 기능\n",
    "- torchvison.transforms 서브모듈\n",
    "    * 이미지 크기조절\n",
    "    * 이미지 정규화\n",
    "    * 이미지 자르기\n",
    "    * 이미지 화전등등 다양한기능제공\n",
    "    * 이미지 데이터 타입 ==> Pillow Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                            # 이미지 ndarray\n",
    "from torchvision import transforms \n",
    "from torchvision.transforms import v2    # 이미지 JpegImage\n",
    "import torch \n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH='../image/'\n",
    "IMG_FILE=IMG_PATH+'arona.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_img=cv2.imread(IMG_FILE)\n",
    "cv_img=cv2.cvtColor(cv_img,cv2.COLOR_BGR2RGB)\n",
    "pil_img=Image.open(IMG_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(cv_img) : <class 'numpy.ndarray'>\n",
      "type(pil_img) : <class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    }
   ],
   "source": [
    "print(f'type(cv_img) : {type(cv_img)}')\n",
    "print(f'type(pil_img) : {type(pil_img)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 인스턴스와 메서드\n",
    "    * 인스턴스(Instance) : 메모리(힙)에 존제하는 (저장된) 데이터의 종류를 명시해서 부르는 용어\n",
    "        - 예) 정수 인스턴스, vgg인스턴스, 사람인스턴스\n",
    "    * 속성(Attribute/Field) : 클레스가 가지는 특징, 외형, 내형, 성격\n",
    "    * 메서드(Method) : 클레스가 가지는 기능/역할 ==> 문법구조는 함수와 동일"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "class A:\n",
    "\n",
    "    # 인스턴스를 생성해주는 메서드\n",
    "    def __init__(self,num,loc):\n",
    "        self.num=num    # 인스턴스 속성\n",
    "        self.loc=loc    # 인스턴스 속성\n",
    "        print('__init__()')\n",
    "\n",
    "    # 연산자(+,-,*,/,//,%,**)기능과 연결된 매직 메서드\n",
    "    def __add__(self,other):\n",
    "        print('__add__()')\n",
    "        return self.num+other.num\n",
    "    \n",
    "    def __mul__(self,other):\n",
    "        print('__add__()')\n",
    "        return self.num*other.num\n",
    "    \n",
    "    # 인스턴스 변수명으로 호출되는 메서드\n",
    "    def __call__(self,value):\n",
    "        print('__call__()')\n",
    "    # A클레스로 생선된 인스턴스 전용의 메서드\n",
    "    def test(self,food):\n",
    "        print(self.loc,food)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__()\n",
      "__init__()\n",
      "대구\n",
      "대구 치맥\n",
      "__add__()\n",
      "110\n",
      "__add__()\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# 인스턴스 생성\n",
    "a1=A(10,'대구')\n",
    "a2=A(100,'부산')\n",
    "print(a1.loc)\n",
    "a1.test('치맥')\n",
    "print(a1+a2)\n",
    "print(a1*a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__()\n",
      "__call__()\n",
      "\n",
      "__call__()\n"
     ]
    }
   ],
   "source": [
    "A(5,'경주')(8888)\n",
    "print()\n",
    "a1(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Resize 이미지 크기변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900, 3)\n",
      "torch.Size([3, 40, 20])\n"
     ]
    }
   ],
   "source": [
    "### v2.resize()클레스\n",
    "# img => tensor\n",
    "print(cv_img.shape)\n",
    "imgTS=v2.ToImage()(cv_img)\n",
    "imgTS2=v2.Resize(size=(40,20),interpolation=v2.InterpolationMode.BILINEAR)(imgTS)\n",
    "print(imgTS2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 900, 3)\n",
      "torch.Size([3, 40, 20])\n"
     ]
    }
   ],
   "source": [
    "### v2.Compse()클레스 : 이미지에 진행할 여러가지 전처리를 하나로 묶음 처리즉, pipeline 설정\n",
    "print(cv_img.shape)\n",
    "tras=v2.Compose([v2.ToImage(),v2.Resize(size=(40,20),interpolation=v2.InterpolationMode.BILINEAR)])\n",
    "imgTS2=tras(cv_img)\n",
    "print(imgTS2.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
