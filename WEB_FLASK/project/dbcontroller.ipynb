{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       습도  강수량    기온   풍속  한식  글로벌  패스트푸드\n",
      "0      75    0  -2.7  0.9  11    9     26\n",
      "1      67    0  -1.8  1.2  10    6     21\n",
      "2      72    0   0.6  1.0  25    9     11\n",
      "3      74    0   0.2  0.7  34   13     21\n",
      "4      73    0   0.0  0.9  39   15     23\n",
      "...    ..  ...   ...  ...  ..  ...    ...\n",
      "74501  94    0  16.3  1.0  28   12     49\n",
      "74502  94    0  16.5  2.2  15    6     33\n",
      "74503  91    0  17.1  0.7  12    4     25\n",
      "74504  90    0  17.5  1.2   4    3     19\n",
      "74505  90    0  18.2  2.1   2    1      7\n",
      "\n",
      "[74506 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchmetrics.regression import R2Score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# SQLAlchemy 연결 문자열 (DBeaver와 같은 서버 정보 사용)\n",
    "engine = create_engine('mysql+pymysql://root5:5555@155.230.153.151:3306/db5')\n",
    "\n",
    "# SQL 쿼리 실행 후 데이터프레임으로 가져오기\n",
    "query = \"SELECT * FROM `deli2`\"  # 테이블 이름을 백틱으로 감쌈\n",
    "dataDF = pd.read_sql(query, engine)\n",
    "\n",
    "# 데이터프레임 출력\n",
    "print(dataDF)\n",
    "\n",
    "# 데이터 전처리\n",
    "for i in dataDF.index:\n",
    "    cnt = 0\n",
    "    for data in dataDF.loc[i]:\n",
    "        if data == 0:\n",
    "            cnt += 1\n",
    "        if cnt > 8:\n",
    "            dataDF.drop(index=i, axis=0, inplace=True)  # 행 삭제\n",
    "            break\n",
    "\n",
    "dataDF.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# deliDF 초기화 및 데이터 전처리\n",
    "deliDF = pd.DataFrame()\n",
    "deliDF['평균습도'] = dataDF['습도']\n",
    "deliDF['총강수량'] = dataDF['강수량']\n",
    "deliDF['평균기온'] = dataDF['기온']\n",
    "deliDF['평균풍속'] = dataDF['풍속']\n",
    "deliDF['한식'] = dataDF['한식']\n",
    "deliDF['글로벌'] = dataDF['글로벌']\n",
    "deliDF['패스트푸드'] = dataDF['패스트푸드']\n",
    "deliDF['총배달건수'] = deliDF['한식'] + deliDF['글로벌'] + deliDF['패스트푸드']\n",
    "deliDF['한식'] = deliDF['한식'] / deliDF['총배달건수']*100\n",
    "deliDF['글로벌'] = deliDF['글로벌'] / deliDF['총배달건수']*100\n",
    "deliDF['패스트푸드'] = deliDF['패스트푸드'] / deliDF['총배달건수']*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>평균습도</th>\n",
       "      <th>총강수량</th>\n",
       "      <th>평균기온</th>\n",
       "      <th>평균풍속</th>\n",
       "      <th>한식</th>\n",
       "      <th>글로벌</th>\n",
       "      <th>패스트푸드</th>\n",
       "      <th>총배달건수</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>23.913043</td>\n",
       "      <td>19.565217</td>\n",
       "      <td>56.521739</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>27.027027</td>\n",
       "      <td>16.216216</td>\n",
       "      <td>56.756757</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55.555556</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>19.117647</td>\n",
       "      <td>30.882353</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>50.649351</td>\n",
       "      <td>19.480519</td>\n",
       "      <td>29.870130</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74501</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.460674</td>\n",
       "      <td>13.483146</td>\n",
       "      <td>55.056180</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74502</th>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>27.777778</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74503</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>29.268293</td>\n",
       "      <td>9.756098</td>\n",
       "      <td>60.975610</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74504</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>15.384615</td>\n",
       "      <td>11.538462</td>\n",
       "      <td>73.076923</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74505</th>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74506 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       평균습도  총강수량  평균기온  평균풍속         한식        글로벌      패스트푸드  총배달건수\n",
       "0        75     0  -2.7   0.9  23.913043  19.565217  56.521739     46\n",
       "1        67     0  -1.8   1.2  27.027027  16.216216  56.756757     37\n",
       "2        72     0   0.6   1.0  55.555556  20.000000  24.444444     45\n",
       "3        74     0   0.2   0.7  50.000000  19.117647  30.882353     68\n",
       "4        73     0   0.0   0.9  50.649351  19.480519  29.870130     77\n",
       "...     ...   ...   ...   ...        ...        ...        ...    ...\n",
       "74501    94     0  16.3   1.0  31.460674  13.483146  55.056180     89\n",
       "74502    94     0  16.5   2.2  27.777778  11.111111  61.111111     54\n",
       "74503    91     0  17.1   0.7  29.268293   9.756098  60.975610     41\n",
       "74504    90     0  17.5   1.2  15.384615  11.538462  73.076923     26\n",
       "74505    90     0  18.2   2.1  20.000000  10.000000  70.000000     10\n",
       "\n",
       "[74506 rows x 8 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deliDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41909, 4), (18627, 4), (13970, 4)\n",
      "(41909,), (18627,), (13970,)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch 모델 정의\n",
    "class IrisRegModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1. 입력층 4 -> 16\n",
    "        self.in_layer = nn.Linear(4, 16)\n",
    "        \n",
    "        # 2~10. 은닉층 (LeakyReLU 포함)\n",
    "        self.hd_layer1 = nn.Linear(16, 32)\n",
    "        self.hd_layer2 = nn.Linear(32, 64)\n",
    "        self.hd_layer3 = nn.Linear(64, 128)\n",
    "        self.hd_layer4 = nn.Linear(128, 64)\n",
    "        self.hd_layer5 = nn.Linear(64, 32)\n",
    "        self.hd_layer6 = nn.Linear(32, 64)\n",
    "        self.hd_layer7 = nn.Linear(64, 32)\n",
    "        self.hd_layer8 = nn.Linear(32, 16)\n",
    "        self.hd_layer9 = nn.Linear(16, 8)\n",
    "        \n",
    "        # 11. 출력층 8 -> 1\n",
    "        self.out_layer = nn.Linear(8, 1)\n",
    "\n",
    "        # LeakyReLU (alpha=0.01 사용)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.01)\n",
    "\n",
    "    def forward(self, input_data):\n",
    "        # 1. 입력층\n",
    "        y = self.leaky_relu(self.in_layer(input_data))\n",
    "        \n",
    "        # 2~10. 은닉층들에 LeakyReLU 적용\n",
    "        y = self.leaky_relu(self.hd_layer1(y))\n",
    "        y = self.leaky_relu(self.hd_layer2(y))\n",
    "        y = self.leaky_relu(self.hd_layer3(y))\n",
    "        y = self.leaky_relu(self.hd_layer4(y))\n",
    "        y = self.leaky_relu(self.hd_layer5(y))\n",
    "        y = self.leaky_relu(self.hd_layer6(y))\n",
    "        y = self.leaky_relu(self.hd_layer7(y))\n",
    "        y = self.leaky_relu(self.hd_layer8(y))\n",
    "        y = self.leaky_relu(self.hd_layer9(y))\n",
    "        \n",
    "        # 11. 출력층 (활성화 함수 없음, 회귀이므로)                                     q                                                                                                                               \n",
    "\n",
    "        \n",
    "        return self.out_layer(y)\n",
    " \n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = featureDF.shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor([self.targetDF.iloc[index]])  # 2D로 변환\n",
    "        return featureTS, targetTS  \n",
    "\n",
    "# 학습 진행 관련 설정\n",
    "EPOCH = 1000\n",
    "BATCH_SIZE = 10\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.0001  \n",
    "\n",
    "targetDF = deliDF['패스트푸드']  # 타겟 데이터 설정\n",
    "featureDF = deliDF.drop(columns=['패스트푸드', '총배달건수','한식','글로벌'])  # 특성 데이터 설정\n",
    "\n",
    "# 모델 인스턴스\n",
    "model = IrisRegModel()\n",
    "# 데이터셋 인스턴스\n",
    "X_train, X_test, y_train, y_test = train_test_split(featureDF, targetDF, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=1)\n",
    "\n",
    "print(f'{X_train.shape}, {X_test.shape}, {X_val.shape}')\n",
    "print(f'{y_train.shape}, {y_test.shape}, {y_val.shape}')\n",
    "\n",
    "trainDS = IrisDataset(X_train, y_train)\n",
    "valDS = IrisDataset(X_val, y_val)\n",
    "testDS = IrisDataset(X_test, y_test)\n",
    "\n",
    "# 데이터 로더 인스턴스\n",
    "trainDL = DataLoader(trainDS, batch_size=BATCH_SIZE)\n",
    "valDL=DataLoader(valDS,batch_size=len(valDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Train Loss: 0.3160, Train R² Score: 0.9944, Validation Loss: 21.0740, Validation R² Score: -1.0110\n",
      "Epoch [2/1000], Train Loss: 0.0869, Train R² Score: 0.9999, Validation Loss: 21.0838, Validation R² Score: -1.0141\n",
      "Epoch [3/1000], Train Loss: 0.0837, Train R² Score: 0.9999, Validation Loss: 21.0647, Validation R² Score: -1.0101\n",
      "Epoch [4/1000], Train Loss: 0.0790, Train R² Score: 0.9999, Validation Loss: 21.0748, Validation R² Score: -1.0119\n",
      "Epoch [5/1000], Train Loss: 0.0856, Train R² Score: 0.9999, Validation Loss: 20.9898, Validation R² Score: -0.9961\n",
      "Epoch [6/1000], Train Loss: 0.0767, Train R² Score: 0.9999, Validation Loss: 20.9933, Validation R² Score: -0.9962\n",
      "Epoch [7/1000], Train Loss: 0.0816, Train R² Score: 0.9999, Validation Loss: 20.9502, Validation R² Score: -0.9888\n",
      "Epoch [8/1000], Train Loss: 0.0824, Train R² Score: 0.9999, Validation Loss: 20.9253, Validation R² Score: -0.9834\n",
      "Epoch [9/1000], Train Loss: 0.0802, Train R² Score: 0.9999, Validation Loss: 20.9082, Validation R² Score: -0.9800\n",
      "Epoch [10/1000], Train Loss: 0.0798, Train R² Score: 0.9999, Validation Loss: 20.8908, Validation R² Score: -0.9763\n",
      "Epoch [11/1000], Train Loss: 0.0831, Train R² Score: 0.9999, Validation Loss: 20.8767, Validation R² Score: -0.9741\n",
      "Epoch [12/1000], Train Loss: 0.0812, Train R² Score: 0.9999, Validation Loss: 20.8615, Validation R² Score: -0.9705\n",
      "Epoch [13/1000], Train Loss: 0.0768, Train R² Score: 0.9999, Validation Loss: 20.8308, Validation R² Score: -0.9650\n",
      "Epoch [14/1000], Train Loss: 0.0839, Train R² Score: 0.9999, Validation Loss: 20.8072, Validation R² Score: -0.9603\n",
      "Epoch [15/1000], Train Loss: 0.0788, Train R² Score: 0.9999, Validation Loss: 20.7664, Validation R² Score: -0.9533\n",
      "Epoch [16/1000], Train Loss: 0.0784, Train R² Score: 0.9999, Validation Loss: 20.7698, Validation R² Score: -0.9529\n",
      "Epoch [17/1000], Train Loss: 0.0791, Train R² Score: 0.9999, Validation Loss: 20.7474, Validation R² Score: -0.9492\n",
      "Epoch [18/1000], Train Loss: 0.0801, Train R² Score: 0.9999, Validation Loss: 20.7635, Validation R² Score: -0.9508\n",
      "Epoch [19/1000], Train Loss: 0.0793, Train R² Score: 0.9999, Validation Loss: 20.7206, Validation R² Score: -0.9437\n",
      "Epoch [20/1000], Train Loss: 0.0769, Train R² Score: 0.9999, Validation Loss: 20.7152, Validation R² Score: -0.9421\n",
      "Epoch [21/1000], Train Loss: 0.0782, Train R² Score: 0.9999, Validation Loss: 20.6828, Validation R² Score: -0.9357\n",
      "Epoch [22/1000], Train Loss: 0.0808, Train R² Score: 0.9999, Validation Loss: 20.6405, Validation R² Score: -0.9276\n",
      "Epoch [23/1000], Train Loss: 0.0733, Train R² Score: 0.9999, Validation Loss: 20.6596, Validation R² Score: -0.9316\n",
      "Epoch [24/1000], Train Loss: 0.0811, Train R² Score: 0.9999, Validation Loss: 20.6506, Validation R² Score: -0.9300\n",
      "Epoch [25/1000], Train Loss: 0.0757, Train R² Score: 0.9999, Validation Loss: 20.6445, Validation R² Score: -0.9278\n",
      "Epoch [26/1000], Train Loss: 0.0783, Train R² Score: 0.9999, Validation Loss: 20.6296, Validation R² Score: -0.9256\n",
      "Epoch [27/1000], Train Loss: 0.0712, Train R² Score: 1.0000, Validation Loss: 20.5943, Validation R² Score: -0.9188\n",
      "Epoch [28/1000], Train Loss: 0.0748, Train R² Score: 0.9999, Validation Loss: 20.5891, Validation R² Score: -0.9181\n",
      "Epoch [29/1000], Train Loss: 0.0770, Train R² Score: 0.9999, Validation Loss: 20.5768, Validation R² Score: -0.9157\n",
      "Epoch [30/1000], Train Loss: 0.0737, Train R² Score: 0.9999, Validation Loss: 20.5744, Validation R² Score: -0.9148\n",
      "Epoch [31/1000], Train Loss: 0.0723, Train R² Score: 1.0000, Validation Loss: 20.5874, Validation R² Score: -0.9169\n",
      "Epoch [32/1000], Train Loss: 0.0786, Train R² Score: 0.9999, Validation Loss: 20.5423, Validation R² Score: -0.9094\n",
      "Epoch [33/1000], Train Loss: 0.0744, Train R² Score: 0.9999, Validation Loss: 20.5350, Validation R² Score: -0.9072\n",
      "Epoch [34/1000], Train Loss: 0.0727, Train R² Score: 0.9999, Validation Loss: 20.5476, Validation R² Score: -0.9094\n",
      "Epoch [35/1000], Train Loss: 0.0760, Train R² Score: 0.9999, Validation Loss: 20.5105, Validation R² Score: -0.9028\n",
      "Epoch [36/1000], Train Loss: 0.0809, Train R² Score: 0.9999, Validation Loss: 20.5295, Validation R² Score: -0.9057\n",
      "Epoch [37/1000], Train Loss: 0.0715, Train R² Score: 0.9999, Validation Loss: 20.4901, Validation R² Score: -0.8990\n",
      "Epoch [38/1000], Train Loss: 0.0730, Train R² Score: 0.9999, Validation Loss: 20.5074, Validation R² Score: -0.9021\n",
      "Epoch [39/1000], Train Loss: 0.0747, Train R² Score: 0.9999, Validation Loss: 20.5016, Validation R² Score: -0.9006\n",
      "Epoch [40/1000], Train Loss: 0.0710, Train R² Score: 0.9999, Validation Loss: 20.4904, Validation R² Score: -0.8983\n",
      "Epoch [41/1000], Train Loss: 0.0760, Train R² Score: 0.9999, Validation Loss: 20.4745, Validation R² Score: -0.8954\n",
      "Epoch [42/1000], Train Loss: 0.0725, Train R² Score: 0.9999, Validation Loss: 20.4612, Validation R² Score: -0.8933\n",
      "Epoch [43/1000], Train Loss: 0.0738, Train R² Score: 0.9999, Validation Loss: 20.4639, Validation R² Score: -0.8938\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 7.4929, Train R² Score: 0.0159, Validation Loss: 18.4376, Validation R² Score: -0.5729\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 6.6668, Train R² Score: 0.2894, Validation Loss: 19.5849, Validation R² Score: -0.7856\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 5.2443, Train R² Score: 0.4793, Validation Loss: 33.2221, Validation R² Score: -5.3327\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 3.6871, Train R² Score: 0.5845, Validation Loss: 29.9288, Validation R² Score: -2.9124\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 3.7542, Train R² Score: 0.2280, Validation Loss: 20.1652, Validation R² Score: -0.8731\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 7.6951, Train R² Score: 0.4254, Validation Loss: 32.9817, Validation R² Score: -3.9553\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 8.1692, Train R² Score: 0.5015, Validation Loss: 28.5402, Validation R² Score: -2.8176\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.7038, Train R² Score: 0.9583, Validation Loss: 31.5129, Validation R² Score: -4.0655\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.9666, Train R² Score: 0.9682, Validation Loss: 24.5213, Validation R² Score: -2.5527\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 2.2560, Train R² Score: 0.9160, Validation Loss: 42.4474, Validation R² Score: -11.4253\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 4.4848, Train R² Score: 0.4344, Validation Loss: 26.3331, Validation R² Score: -2.6644\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.6771, Train R² Score: 0.9955, Validation Loss: 27.6999, Validation R² Score: -2.6281\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.9605, Train R² Score: 0.8761, Validation Loss: 28.9446, Validation R² Score: -2.8274\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.8811, Train R² Score: 0.9468, Validation Loss: 32.5210, Validation R² Score: -4.7792\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.2266, Train R² Score: 0.9815, Validation Loss: 35.2857, Validation R² Score: -5.1921\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.0115, Train R² Score: 0.9544, Validation Loss: 26.3309, Validation R² Score: -2.2811\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.8815, Train R² Score: 0.9807, Validation Loss: 26.2156, Validation R² Score: -2.1477\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.2662, Train R² Score: 0.9700, Validation Loss: 28.3373, Validation R² Score: -2.8190\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.7294, Train R² Score: 0.9661, Validation Loss: 24.8212, Validation R² Score: -1.7890\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 3.1504, Train R² Score: 0.8149, Validation Loss: 36.3202, Validation R² Score: -5.2841\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.8400, Train R² Score: 0.8857, Validation Loss: 25.3935, Validation R² Score: -2.0069\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 2.4745, Train R² Score: 0.8728, Validation Loss: 25.1825, Validation R² Score: -1.9660\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.0425, Train R² Score: 0.9657, Validation Loss: 24.7131, Validation R² Score: -1.8781\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 3.2675, Train R² Score: 0.7037, Validation Loss: 24.8075, Validation R² Score: -2.1912\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.3363, Train R² Score: 0.9204, Validation Loss: 26.8764, Validation R² Score: -2.5903\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.8064, Train R² Score: 0.9536, Validation Loss: 21.1064, Validation R² Score: -1.1077\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.4845, Train R² Score: 0.9816, Validation Loss: 21.5303, Validation R² Score: -1.1894\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 0.7621, Train R² Score: 0.9842, Validation Loss: 20.7597, Validation R² Score: -1.0041\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 2.6065, Train R² Score: 0.8996, Validation Loss: 32.4076, Validation R² Score: -3.8961\n",
      "성능 및 손실 개선이 없어서 학습 중단\n",
      "Epoch [1/1000], Train Loss: 1.5172, Train R² Score: 0.9672, Validation Loss: 32.2077, Validation R² Score: -6.4969\n",
      "성능 및 손실 개선이 없어서 학습 중단\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 26\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m             )\n\u001b[1;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    217\u001b[0m         group,\n\u001b[0;32m    218\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    223\u001b[0m         state_steps,\n\u001b[0;32m    224\u001b[0m     )\n\u001b[1;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\envs\\WEB_AI\\lib\\site-packages\\torch\\optim\\adam.py:380\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    379\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 380\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    383\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 최적화 인스턴스\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "# 손실함수 인스턴스\n",
    "reqLoss = nn.L1Loss()  \n",
    "\n",
    "LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []]\n",
    "CNT = len(trainDL)\n",
    "\n",
    "# 학습 모니터링/스케줄링 설정\n",
    "BREAK_CNT = 0\n",
    "LIMIT_VALUE = 10 \n",
    "\n",
    "for feature,target in trainDL:\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        loss_total, score_total = 0, 0\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            pre_y = model(feature)\n",
    "            loss = reqLoss(pre_y, target)\n",
    "            loss_total += loss.item()\n",
    "            score = R2Score()(pre_y, target)\n",
    "            score_total += score\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_featureTS = torch.FloatTensor(valDS.featureDF.values)\n",
    "            val_targetTS = torch.FloatTensor(valDS.targetDF.values).view(-1, 1)  # 2D로 변환\n",
    "            pre_val = model(val_featureTS)\n",
    "            loss_val = reqLoss(pre_val, val_targetTS)\n",
    "            score_val = R2Score()(pre_val, val_targetTS)\n",
    "\n",
    "        import os\n",
    "\n",
    "\n",
    "        # 손실과 성능 출력\n",
    "        print(f'Epoch [{epoch + 1}/{EPOCH}], '\n",
    "            f'Train Loss: {loss_total / CNT:.4f}, '\n",
    "            f'Train R² Score: {score_total / CNT:.4f}, '\n",
    "            f'Validation Loss: {loss_val.item():.4f}, '\n",
    "            f'Validation R² Score: {score_val.item():.4f}')\n",
    "\n",
    "        LOSS_HISTORY[0].append(loss_total / CNT)\n",
    "        SCORE_HISTORY[0].append(score_total / CNT)\n",
    "        LOSS_HISTORY[1].append(loss_val.item())\n",
    "        SCORE_HISTORY[1].append(score_val.item())\n",
    "\n",
    "            # 모델 폴더가 없다면 생성\n",
    "        if not os.path.exists('model/'):\n",
    "            os.mkdir('model/')\n",
    "\n",
    "        # test loss가 최저인점 저장\n",
    "        if len(LOSS_HISTORY[1])==1:\n",
    "            torch.save(model,f'model/best_model2.pth')\n",
    "\n",
    "\n",
    "        elif LOSS_HISTORY[1][-1]<=min(LOSS_HISTORY[1]):\n",
    "            torch.save(model,f'model/best_model2.pth')\n",
    "\n",
    "        if len(LOSS_HISTORY[0]) >= 2:\n",
    "            if LOSS_HISTORY[1][-1] >= LOSS_HISTORY[1][-2]:\n",
    "                BREAK_CNT += 1\n",
    "        \n",
    "        if BREAK_CNT > LIMIT_VALUE:\n",
    "            print('성능 및 손실 개선이 없어서 학습 중단')\n",
    "            break  # 학습 중단 시 루프를 종료합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1591], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(r'C:\\KDT-2024\\WEB_FLASK\\project\\PROWEB\\models\\best_model2.pth',weights_only=False)\n",
    "model(torch.FloatTensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
